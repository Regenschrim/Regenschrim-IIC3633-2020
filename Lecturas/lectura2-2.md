# Lectura 2 - 2

En este trabajo se critica a modelos anteriores diciendo que calculan la probabilidad de elegir un item, no hacen una recomendación (una lista de elementos ordenados por algún parámetro). También se critica a los algoritmos de machine learning porque no aprenden de lo implicito (se ignoran valores desconocidos).

En este algortimo se utiliza un descenso de gradiente basado en bootstrap sampling sobre tripletas (usuario, item_1, item_2). Se aprende de forma offline y se expande luego a un escenario online.

Se utiliza una función de verosimilitud que esta sujeta a ciertas propiedades dentro del ranking: totalidad, antisimetría y transitividad. Para esto se usa una función logística sigmoidal. También se introduce un función de distribución sobre *theta* que es una normal con media cero y con varianza una matriz *Epsilon sub theta*, la cual es escrita como *lambda \* I*. Y al reemplazar y aplicar logaritmo sobre la función de verosimilitud, se obtiene que *lambda* son los parámetros de regularización. Además, antes se define que para poder hacer un ranking personalizado, se cambia la función de probabilidad que indica que el usuario prefiere un ítem por sobre otro.

Para este problema en particular no se recomienda un descenso de gradiente normal, si no uno estocástico. El descenso de gradiente normal va en la dirección correcta pero le toma mucho tiempo en convergir. Esto es también debido a que si hay un ítem que se tiene que comparar con muchos otros y este ítem domina la gradiente, se debería elegir un learning rate super pequeño para que funcione. También se complica la regularización.

Por esta razón se recomienda el descenso de gradiente estocástico, ya que se puede realizar un random de las tripletas, disminuyendo la probabilidad de elegir el mismo usuario y primer ítem, lo que se traduce en que el descenso no quede estancado actualizando valores.Se utilizó el descenso de gradiente estocástico sobre tripletas en el modelo de factorización de matrices y k-NN, ya que este cumple su función mejor. Sin embargo, se adoptó el cálculo sobre tripletas a pares usuario-ítem para que puedan ser utilizados en estos algoritmos.

Finalmente, se compararon rendimientos con la métrica AUC (donde lo mejor es 1 y 0 lo peor). En ambos datasets de prueba se ve que la optimización que se desarrolló tiene un mejor resultado que el resto de las técnicas, además de cumplir la tarea que se suponía que debiese cumplir. Respecto a esto, se dice que la mejor forma de obtener mejores es resultados es saber que es lo que se quiere lograr y optimizar respecto a ese objetivo.

En general, es un paper super técnico y muy orientado al conocimiento matemático para su comprensión. En lo personal, se me hizo muy difícil comprender muchas de las razones de diseño dentro de las optimización: se entienden los cálculos pero no el razonamiento o el objetivo que se quiere lograr con ellos. No entendí bien la optimización en que se usó la función de probabilidad y su parámetro *theta* y como es que se llegó a reemplazar por una sigmoide que explica la relación entre un usuario y dos ítems.

Por otro lado, no sé si quedó bien explicado pero se mide la preferencia de un usuario *u* sobre los ítems *i* y *j*, donde ambos ítems son todas las combinaciones posibles de ítems. ¿Qué ocurre cuando tenemos valores similares para varios ítems? Se supone que se cumple una propiedad de relación asimétrica, pero no puedo ver como funcionaría el ranking frente a varios ítems con la misma preferencia ¿Se ordenan de forma arbitraría o es muy difícil que este caso llegue a ocurrir?
